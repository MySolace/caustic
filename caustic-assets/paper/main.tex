\documentclass[12pt]{article}

% Packages.
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{amsthm}
\usepackage{hyperref}

\begin{document}

% Title.
\title{Caustic: Reinventing Database Transactions}
\author{Ashwin Madavan}
\maketitle

% Abstract.
\begin{abstract}
Databases are either easy to use or to scale. For example, relational databases were popularized in
large part because of the programmability of SQL. However, this programmability comes at an
incredible expense. Relational databases are notoriously difficult to support at scale, and so
developers have increasingly turned toward more specialized NoSQL systems that scale well be
shedding functionality. Developers are not only forced to choose between productivity and
performance, but also stark differences between query languages makes their choice of database
effectively permanent. Even databases that claim to support the same SQL standard only implement
incompatible subsets of its functionality. The lack of a truly uniform interface tightly couples
databases and the procedures that are executed against them. Caustic is both a syntax for expressing
transactions and a runtime for executing them on arbitrary key-value stores, that is both
straightforward to use and simple to integrate.
\end{abstract}

% Runtime
\section{Runtime}
  The runtime is responsible for executing transactions on arbitrary key-value stores. Runtimes
  implement Multiversion Concurrency Controls over any key-value store that satisfies an minimal
  interface.

  \subsection{Representation}
    A \texttt{Transaction} is represented by an abstract-syntax tree. A \texttt{Literal} corresponds
    to a leaf of this syntax tree, and an \texttt{Expression} corresponds to a node. The runtime
    respects three different types of literals (\texttt{Real}, \texttt{Text}, and \texttt{Flag}) and
    thirty different kinds of expressions. With just these types and operations, the runtime is able
    to emulate a modern programming language complete with conditional branching, loops, and local
    variables.

  \subsection{Execution}
    Transactions are executed through repeated partial evaluation, according to the following
    procedure.

    \begin{itemize}
      \item \textbb{Fetch}: Call \texttt{get} on all keys that are read and written by the
        transaction and add the returned revisions to a local snapshot. In order to guarantee
        snapshot isolation, \texttt{get} is only called when a key is read or written for the
        first time. By batching reads and writes and avoiding duplicate fetches, the runtime is
        guaranteed to perform a minimal number of roundtrips to and from the database.
      \item \textbb{Evaluate}: Recursively replace all expressions that have literal operands with
        their corresponding literal result. For example, add(real(1), sub(real(0), real(2)))
        returns real(-1). The result of all write expressions is saved to a local buffer and all
        read expressions return the latest value of the key in either the local buffer or snapshot.
      \item \textbb{Repeat}: Re-evaluate the transaction until it reduces to a single literal
        value. Because all expressions with literal operands return a literal value, all
        transactions eventually reduce to a literal.
    \end{itemize}

  \subsection{Integrated Caching}
    MVCC allows the runtime to cache incoherently without sacrificing data integrity. The runtime
    speculates about the value of a key by reading a potentially stale version from cache, and then
    validate the cached versions when they commit. Multilevel, write-through caching is directly
    integrated into the runtime:

    \begin{itemize}
      \item Keys are updated on cache miss.
      \item Keys are automatically updated after successful transactions.
      \item Keys are automatically invalidated after conflicting transactions.
    \end{itemize}

    \subsubsection{Effect of Contention}
      While the implementation of caching is fault tolerant, it is particularly vulnerable to
      thrashing under contention. Consider if runtime A and runtime B read a key K from cache. A
      updates the value of K, and then subsequently updates the value of K in cache. When B tries to
      update the value of K it will cause a conflict, and so it will subsequently invalidate K in
      cache.

      A potential solution might be to remove the invalidation step from the procedure; however, the
      implementation would no longer be fault tolerant. Consider if A updates K but fails to write
      the new value to cache. Now the value in cache will remain stale until its evicted, but a key
      under high contention may never be evicted from cache.

  \subsection{Performance}

    \subsubsection{Effect of Transaction Size}
      The runtime has been empirically shown to scale linearly with transaction size.

    \subsubsection{Effect of Read or Write Skew}
      The quantity of read and write expressions will surely impact the performance profile of the
      runtime. However, the difference in performance is an artifact of the choice of underlying
      key-value store and not due to any inherent bias in the runtime.

    \subsubsection{Effect of Contention}
      What happens to performance under contention? The number of retries required to execute a
      transaction may be modeled as a negative binomial distribution in which the probability of
      success $p$ is the contention probability. Therefore, $A = 1 + NB(1, p)$ is the distribution
      of attempts. Known results about the negative binomial distribution, may be used to make
      predictions about the mean and variance of transaction execution latency under contention. For
      example, the mean number of attempts $\bar{A} = 1 + \frac{p}{1 - p} = \frac{1}{1 - p}$. The
      contention probability is determined by a number of factors including: the number of keys that
      are read and written, the number of database reads and writes, and the latency of database
      reads and write.

% Syntax
\section{Syntax}
  While the language exposed by the runtime is robust and fully-featured, it can become verbose and
  unintuitive as transactions get larger in size and broader in scope. In this section, we'll
  introduce the Caustic programming language.

  \subsection{Why Caustic?}
    Relational databases have remained dominant particularly because of the programmability of SQL.
    SQL provides developers with robust schemas that make it easy to structure and debug database
    queries. However, relational database are notoriously difficult to support at scale, and so
    developers are increasingly turning towards more specialized NoSQL systems that scale well by
    shedding functionality.

    While SQL has previously enjoyed remarkable popularity, the language is deeply flawed. In his
    letter entitled "Some Principles of Good Language Design", CJ Date outlines a number of these
    flaws as well as a criteria for evaluating languages in general. Date argues that well-designed
    languages should have a consistent syntax, a canonical implementation, a terse grammar, and an
    intuitive structure and provides examples that show how SQL fails to satisfy each of these
    fundamental requirements.

  \subsection{Automatic Concurrency}
    Because all programs written in Caustic compile into transactions on the Caustic runtime, all
    programs are automatically thread-safe. Developers no longer have to worry about fancy
    synchronization mechanisms in order to build parallelizable programs.

  \subsection{Uniform Interface}
    Every database has its own query language. Even databases that implement the same SQL
    specification usually support disparate subsets of the language. This has the effect of tightly
    coupling the underlying database and the procedures that are run against it. Caustic provides
    a uniform interface over arbitrary databases, which allows programmers to select whichever
    underlying database is most appropriate for their use-case without modifying the code in any
    way shape or form.

  \subsection{Interoperability}
    Because of the simplicity of the Caustic grammar and runtime, the compiler is able to generate
    executable binaries that serve Caustic programs over a variety of mediums over any underlying
    database. Most OLTP applications can be divided into three parts: a database connector
    (eg. SQLAlchemy), a set of stored procedures (eg. Flask), and an external interface
    (eg. REST, Thrift). By specifying their stored procedures in Caustic, programmers can now rely
    on the Caustic compiler to generate the first and third parts for them.

\end{document}
